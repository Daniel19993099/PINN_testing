{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.014598   0.014112  ]\n",
      " [0.014598   0.01610713]]\n",
      "[[43584350.6]\n",
      " [43195861.8]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_x = np.array([[0.014598, 0.014112], [0.014598, 0.016107131]])\n",
    "\n",
    "data_sigma = np.array([[43584350.6], [43195861.8]])  \n",
    "\n",
    "\n",
    "X_test=np.array([[0.014598, 0.014112], [0.014598, 0.016107131]])\n",
    "y_test=np.array([[43584350.6], [43195861.8]]) \n",
    "\n",
    "print(data_x)\n",
    "print(data_sigma)\n",
    "assert data_x is not None, \"data_x is None!\"\n",
    "assert data_sigma is not None, \"data_sigma is None!\"\n",
    "print(type(data_x))  # Should print <class 'numpy.ndarray'>\n",
    "print(type(data_sigma))  # Should print <class 'numpy.ndarray'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\backend\\tensorflow_compat_v1\\tensor.py:25: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "'build' took 0.160848 s\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:168: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 0.269986 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [1.88e+15]    [1.88e+15]    []  \n",
      "1000      [1.88e+15]    [1.88e+15]    []  \n",
      "2000      [1.88e+15]    [1.88e+15]    []  \n",
      "3000      [1.88e+15]    [1.88e+15]    []  \n",
      "4000      [1.88e+15]    [1.88e+15]    []  \n",
      "5000      [1.88e+15]    [1.88e+15]    []  \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 1.88e+15\n",
      "  test loss: 1.88e+15\n",
      "  test metric: []\n",
      "\n",
      "'train' took 2.112179 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deepxde as dde\n",
    "\n",
    "# Use the DataSet data object to create a data-driven task\n",
    "data = dde.data.dataset.DataSet(X_train=data_x, y_train=data_sigma, X_test=X_test, y_test=y_test)\n",
    "\n",
    "# Define the network for σ\n",
    "layer_size = [2] + [50] * 3 + [1]  # 2 inputs (x, y ) -> hidden layers -> 1 output (σ)\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot uniform\"\n",
    "net_sigma = dde.nn.FNN(layer_size, activation,initializer)\n",
    "\n",
    "# Define the model\n",
    "model_sigma = dde.Model(data, net_sigma)\n",
    "\n",
    "# Compile the model with data\n",
    "model_sigma.compile(\"adam\", lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "losshistory, train_state = model_sigma.train(epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267.1882]]\n"
     ]
    }
   ],
   "source": [
    "sigma_A = model_sigma.predict([[2,1]])\n",
    "print(sigma_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def pde_C_L(x, C_L):\n",
    "    dC_L_dt = dde.grad.jacobian(C_L, x, i=0, j=2)\n",
    "    dC_L_dx2 = dde.grad.hessian(C_L, x, i=0, j=0)\n",
    "    dC_L_dy2 = dde.grad.hessian(C_L, x, i=0, j=1)\n",
    "    \n",
    "    C_LA = C_L[:, 0:1]\n",
    "    C_LB = C_L[:, 1:2]\n",
    "\n",
    "    # Assuming data is stored in a 2D NumPy array, where columns represent [x, y, t]\n",
    "    data = np.array(x)\n",
    "    print(data)\n",
    "    # Extract x, y pairs (assume column 0 is x, column 1 is y)\n",
    "    x_y_pairs = data[:,0:2]\n",
    "    print(x_y_pairs)\n",
    "    # Randomly choose one row\n",
    "    random_row = x_y_pairs[np.random.choice(x_y_pairs.shape[0])]\n",
    "    print(random_row)    \n",
    "    sigma_A = model_sigma.predict([random_row]) \n",
    "    print(sigma_A)\n",
    "\n",
    "    \n",
    "\n",
    "    eq2 = dC_L_dt - (1/3.8) * (dC_L_dx2 + dC_L_dy2)\n",
    "    eq1 = C_LA - C_LB * tf.exp(2e10-6*(sigma_A))\n",
    "   \n",
    "    eq=eq1-eq2\n",
    "    return [eq]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]]\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]]\n",
      "[[267.765]\n",
      " [267.765]\n",
      " [267.765]]\n",
      "[array([[-inf],\n",
      "       [-inf],\n",
      "       [-inf]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yesda\\AppData\\Local\\Temp\\ipykernel_37092\\2224600891.py:19: RuntimeWarning: overflow encountered in exp\n",
      "  eq1 = C_LA - C_LB *np.exp(sigma_A)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "def pde_C_L(x, C_L):\n",
    "  \n",
    "    C_LA = C_L[:, 0:1]\n",
    "    C_LB = C_L[:, 1:2]\n",
    "\n",
    "    # Assuming data is stored in a 2D NumPy array, where columns represent [x, y, t]\n",
    "    data = np.array(x)\n",
    "    print(data)\n",
    "    # Extract x, y pairs (assume column 0 is x, column 1 is y)\n",
    "    x_y_pairs = data[:,0:2]\n",
    "    print(x_y_pairs)\n",
    "    # Randomly choose one row\n",
    "    #random_row = x_y_pairs[np.random.choice(x_y_pairs.shape[0])]\n",
    "    #print(random_row)    \n",
    "    sigma_A = model_sigma.predict(x_y_pairs) \n",
    "    print(sigma_A)\n",
    "    eq1 = C_LA - C_LB *np.exp(sigma_A)\n",
    "    return [eq1]\n",
    "\n",
    "\n",
    "x = np.array([[1,1,1], [2,2,2], [3,3,3]])\n",
    "C_L = np.array([[1,2], [3,4], [5,6]])  \n",
    "\n",
    "print(pde_C_L(x, C_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_C_L(x, C_L):\n",
    "    dC_L_dt = dde.grad.jacobian(C_L, x, i=0, j=2)\n",
    "    dC_L_dx2 = dde.grad.hessian(C_L, x, i=0, j=0)\n",
    "    dC_L_dy2 = dde.grad.hessian(C_L, x, i=0, j=1)\n",
    "\n",
    "    eq2 = dC_L_dt - (1/3.8) * (dC_L_dx2 + dC_L_dy2)\n",
    "    return [eq2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "5\n",
      "[5 6]\n"
     ]
    }
   ],
   "source": [
    "x_y_pairs = np.array([[1, 2],\n",
    "                      [3, 4],\n",
    "                      [5, 6],\n",
    "                      [7, 8],\n",
    "                      [9, 10]])\n",
    "\n",
    "# Shape will be (5, 2)\n",
    "print(x_y_pairs.shape)  # Output: (5, 2)\n",
    "\n",
    "# x_y_pairs.shape[0] gives the number of rows, which is 5\n",
    "print(x_y_pairs.shape[0])  # Output: 5\n",
    "\n",
    "# Select a random row\n",
    "random_row = x_y_pairs[np.random.choice(x_y_pairs.shape[0])]\n",
    "print(random_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CSGDifference.uniform_points not implemented. Use random_points instead.\n",
      "Warning: 1000 points required, but 1024 points sampled.\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.029766 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic tf.Tensor (Placeholder_62:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m=\u001b[39m dde\u001b[38;5;241m.\u001b[39mModel(data, net_C_L)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compile the model with the PDE and dataset\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:137\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, lr, loss, metrics, decay, loss_weights, external_trainable_variables)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexternal_trainable_variables \u001b[38;5;241m=\u001b[39m external_trainable_variables\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_tensorflow_compat_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_tensorflow(lr, loss_fn, decay)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:186\u001b[0m, in \u001b[0;36mModel._compile_tensorflow_compat_v1\u001b[1;34m(self, lr, loss_fn, decay)\u001b[0m\n\u001b[0;32m    183\u001b[0m         losses \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weights\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n\u001b[1;32m--> 186\u001b[0m losses_train \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m losses_test \u001b[38;5;241m=\u001b[39m losses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mlosses_test)\n\u001b[0;32m    188\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_sum(losses_train)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:172\u001b[0m, in \u001b[0;36mModel._compile_tensorflow_compat_v1.<locals>.losses\u001b[1;34m(losses_fn)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlosses\u001b[39m(losses_fn):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# Data losses\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mlosses_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(losses, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    176\u001b[0m         losses \u001b[38;5;241m=\u001b[39m [losses]\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\data\\data.py:13\u001b[0m, in \u001b[0;36mData.losses_train\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlosses_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, targets, outputs, loss_fn, inputs, model, aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of losses for training dataset, i.e., constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\data\\pde.py:146\u001b[0m, in \u001b[0;36mPDE.losses\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_num_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 146\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpde\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_pde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m get_num_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauxiliary_var_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[73], line 9\u001b[0m, in \u001b[0;36mpde_C_L\u001b[1;34m(x, C_L)\u001b[0m\n\u001b[0;32m      6\u001b[0m C_LB \u001b[38;5;241m=\u001b[39m C_L[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming data is stored in a 2D NumPy array, where columns represent [x, y, t]\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract x, y pairs (assume column 0 is x, column 1 is y)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:628\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    627\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m dtype\n\u001b[1;32m--> 628\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    629\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert a symbolic tf.Tensor (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to a numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This error may indicate that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to pass a Tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a NumPy call, which is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic tf.Tensor (Placeholder_62:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported."
     ]
    }
   ],
   "source": [
    "# Define the square domain (e.g., 2x2 square with side length L)\n",
    "L = 1.0  # Half-length of the square plate\n",
    "square = dde.geometry.Rectangle([-L, -L], [L, L])\n",
    "\n",
    "# Define the circular hole at the center (radius R)\n",
    "R = 0.1  # Radius of the hole\n",
    "circle = dde.geometry.Disk([0, 0], R)\n",
    "\n",
    "# Geometry and time domain\n",
    "geom = dde.geometry.CSGDifference(square, circle)\n",
    "\n",
    "timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "# Define the initial condition and boundary conditions\n",
    "#ic = dde.icbc.IC(geomtime)\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde_C_L,\n",
    "    [],\n",
    "    num_domain=1000,\n",
    "    num_boundary=150,\n",
    "    num_initial=180,\n",
    "    num_test=1000,\n",
    ")\n",
    "\n",
    "# Network for C_L\n",
    "layer_size = [3] + [50] * 3 + [2]  # 3 inputs (x, y, t) -> hidden layers -> 2 outputs (C_LA, C_LB)\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot uniform\"\n",
    "net_C_L = dde.nn.FNN(layer_size, activation, initializer)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model with the PDE, initial and boundary conditions\n",
    "model= dde.Model(data, net_C_L)\n",
    "\n",
    "# Compile the model with the PDE and dataset\n",
    "model.compile(\"adam\", lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "model.train(epochs=5000)\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume C data is in the format: (x, y, z, t) -> C\n",
    "data_C_L = np.hstack((data_x, t.reshape(-1, 1), data_C.reshape(-1, 1)))  # Combine x, y, z, t with C data\n",
    "\n",
    "# Adding the C_L data as a point set boundary condition\n",
    "observations_C_L = dde.PointSetBC(data_x, data_C, component=0)\n",
    "\n",
    "# Add the C_L data to the model\n",
    "model_C_L = dde.Model(geomtime, pde_C_L, [ic, observations_C_L], net_C_L)\n",
    "\n",
    "# Train the model with both PDE and data-driven loss\n",
    "model_C_L.compile(\"adam\", lr=1e-3)\n",
    "model_C_L.train(epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "y_train: [[10.]\n",
      " [11.]\n",
      " [12.]]\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.032669 s\n",
      "\n",
      "'compile' took 0.255298 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "0         [1.15e+02]    [6.23e-02]    []  \n",
      "1000      [6.62e-02]    [4.88e+01]    []  \n",
      "2000      [4.13e-02]    [5.77e+01]    []  \n",
      "3000      [3.24e-03]    [7.02e+01]    []  \n",
      "4000      [1.19e-07]    [7.36e+01]    []  \n",
      "5000      [6.06e-13]    [7.36e+01]    []  \n",
      "6000      [0.00e+00]    [7.36e+01]    []  \n",
      "7000      [0.00e+00]    [7.36e+01]    []  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m dde\u001b[38;5;241m.\u001b[39mModel(data, net)\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:650\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo iterations for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_name))\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_train_end()\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:668\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[1;34m(self, iterations, display_every)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m    667\u001b[0m )\n\u001b[1;32m--> 668\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:558\u001b[0m, in \u001b[0;36mModel._train_step\u001b[1;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    557\u001b[0m     feed_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mfeed_dict(\u001b[38;5;28;01mTrue\u001b[39;00m, inputs, targets, auxiliary_vars)\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1477\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deepxde as dde\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Example data where each x and y have 3 components\n",
    "X_train = np.array([[1.0], [2.0], [3.0]])  # Shape: (n_samples, 3)\n",
    "y_train = np.array([[10.0], [11.0], [12.0]])  # Shape: (n_samples, 3)\n",
    "# Ensure the data is not None and is correctly shaped\n",
    "print(\"X_train:\", X_train)\n",
    "print(\"y_train:\", y_train)\n",
    "\n",
    "data = dde.data.dataset.DataSet(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "\n",
    "\n",
    "# Define the neural network\n",
    "net = dde.nn.FNN([1] + [50] * 3 + [1], \"tanh\", \"Glorot uniform\")\n",
    "\n",
    "\n",
    "# Create and compile the model\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=0.001)\n",
    "model.train(iterations=20000)\n",
    "# Train the model\n",
    "losshistory, train_state = model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
