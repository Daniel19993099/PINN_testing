{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.014598   0.014112  ]\n",
      " [0.014598   0.01610713]]\n",
      "[[43584350.6]\n",
      " [43195861.8]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\backend\\tensorflow_compat_v1\\tensor.py:25: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "'build' took 0.356271 s\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:168: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "'compile' took 0.559310 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [1.88e+15]    [1.88e+15]    []  \n",
      "1000      [1.88e+15]    [1.88e+15]    []  \n",
      "2000      [1.88e+15]    [1.88e+15]    []  \n",
      "3000      [1.88e+15]    [1.88e+15]    []  \n",
      "4000      [1.88e+15]    [1.88e+15]    []  \n",
      "5000      [1.88e+15]    [1.88e+15]    []  \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 1.88e+15\n",
      "  test loss: 1.88e+15\n",
      "  test metric: []\n",
      "\n",
      "'train' took 5.206884 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import deepxde as dde\n",
    "import tensorflow as tf\n",
    "\n",
    "data_x = np.array([[0.014598, 0.014112], [0.014598, 0.016107131]])\n",
    "\n",
    "data_sigma = np.array([[43584350.6], [43195861.8]])  \n",
    "\n",
    "\n",
    "X_test=np.array([[0.014598, 0.014112], [0.014598, 0.016107131]])\n",
    "y_test=np.array([[43584350.6], [43195861.8]]) \n",
    "\n",
    "print(data_x)\n",
    "print(data_sigma)\n",
    "assert data_x is not None, \"data_x is None!\"\n",
    "assert data_sigma is not None, \"data_sigma is None!\"\n",
    "print(type(data_x))  # Should print <class 'numpy.ndarray'>\n",
    "print(type(data_sigma))  # Should print <class 'numpy.ndarray'>\n",
    "\n",
    "\n",
    "\n",
    "import deepxde as dde\n",
    "\n",
    "# Use the DataSet data object to create a data-driven task\n",
    "data = dde.data.dataset.DataSet(X_train=data_x, y_train=data_sigma, X_test=X_test, y_test=y_test)\n",
    "\n",
    "# Define the network for σ\n",
    "layer_size = [2] + [50] * 3 + [1]  # 2 inputs (x, y ) -> hidden layers -> 1 output (σ)\n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot uniform\"\n",
    "net_sigma = dde.nn.FNN(layer_size, activation,initializer)\n",
    "\n",
    "# Define the model\n",
    "model_sigma = dde.Model(data, net_sigma)\n",
    "\n",
    "# Compile the model with data\n",
    "model_sigma.compile(\"adam\", lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "losshistory, train_state = model_sigma.train(epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_C_L(x, C_L):\n",
    "    dC_L_dt = dde.grad.jacobian(C_L, x, i=0, j=2)\n",
    "    dC_L_dx2 = dde.grad.hessian(C_L, x, i=0, j=0)\n",
    "    dC_L_dy2 = dde.grad.hessian(C_L, x, i=0, j=1)\n",
    "    eq = dC_L_dt - (1/3.8) * (dC_L_dx2 + dC_L_dy2)\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_last = 1.0\n",
    "\n",
    "# Define the constraint for random points A and B\n",
    "def random_point_constraint(model, x_A, y_A, x_B, y_B, model_sigma):\n",
    "    # Get the predictions of sigma for the random points\n",
    "    sigma_A = model_sigma.predict(np.array([[x_A, y_A]]))\n",
    "    sigma_B = model_sigma.predict(np.array([[x_B, y_B]]))\n",
    "\n",
    "    # Define constants for the constraint (e.g., VH, R, T)\n",
    "    VH, R, T = 1.0, 1.0, 1.0  # Adjust based on your problem\n",
    "    exponent = (VH / (R * T)) * (sigma_A - sigma_B)\n",
    "\n",
    "    # Model predictions at the two points\n",
    "    C_A = model.predict(np.array([[x_A, y_A, t_last]]))  # C(x_A, y_A, t_last)\n",
    "    C_B = model.predict(np.array([[x_B, y_B, t_last]]))  # C(x_B, y_B, t_last)\n",
    "\n",
    "    # Return the difference between the constraint equation\n",
    "    return C_A - C_B * np.exp(exponent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred, model, data):\n",
    "    # Compute the standard loss (e.g., mean squared error)\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "    # Add a custom constraint or penalty (e.g., random point constraint)\n",
    "    constraint_loss = 0.0\n",
    "    num_pairs = 10  # Number of random pairs to sample\n",
    "\n",
    "    for _ in range(num_pairs):\n",
    "        # Sample random points\n",
    "        x_A = np.random.uniform(-L, L)\n",
    "        y_A = np.random.uniform(-L, L)\n",
    "        x_B = np.random.uniform(-L, L)\n",
    "        y_B = np.random.uniform(-L, L)\n",
    "\n",
    "        # Calculate the constraint term\n",
    "        sigma_A = model_sigma.predict(np.array([[x_A, y_A]]))\n",
    "        sigma_B = model_sigma.predict(np.array([[x_B, y_B]]))\n",
    "\n",
    "        VH, R, T = 1.0, 1.0, 1.0  # Adjust constants as needed\n",
    "        exponent = (VH / (R * T)) * (sigma_A - sigma_B)\n",
    "        C_A = model.predict(np.array([[x_A, y_A, t_last]]))\n",
    "        C_B = model.predict(np.array([[x_B, y_B, t_last]]))\n",
    "\n",
    "        # Constraint term\n",
    "        constraint_loss += tf.reduce_mean(tf.square(C_A - C_B * np.exp(exponent)))\n",
    "\n",
    "    # Total loss is the sum of the original loss and constraint loss\n",
    "    return mse_loss + constraint_loss / num_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1.0\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # Add the random point constraint loss\n",
    "    constraint_loss = 0.0\n",
    "    num_pairs = 10\n",
    "    \n",
    "    for _ in range(num_pairs):\n",
    "        # Sample random points in the domain\n",
    "        x_A, y_A = np.random.uniform(-L, L), np.random.uniform(-L, L)\n",
    "        x_B, y_B = np.random.uniform(-L, L), np.random.uniform(-L, L)\n",
    "        \n",
    "        # Compute the constraint\n",
    "        sigma_A = model_sigma.predict(np.array([[x_A, y_A]]))\n",
    "        sigma_B = model_sigma.predict(np.array([[x_B, y_B]]))\n",
    "        \n",
    "        VH, R, T = 1.0, 1.0, 1.0\n",
    "        exponent = (VH / (R * T)) * (sigma_A - sigma_B)\n",
    "        \n",
    "        # Predictions for C at random points\n",
    "        C_A = model.predict([[x_A, y_A, t_last]])\n",
    "        C_B = model.predict([[x_B, y_B, t_last]])\n",
    "        \n",
    "        constraint_loss += tf.reduce_mean(tf.square(C_A - C_B * np.exp(exponent)))\n",
    "    \n",
    "    return mse_loss + constraint_loss / num_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CSGDifference.uniform_points not implemented. Use random_points instead.\n",
      "Warning: 1000 points required, but 1024 points sampled.\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.027337 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\nn\\tensorflow_compat_v1\\fnn.py:116: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument `fetch` = None has invalid type \"NoneType\". Cannot be None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m=\u001b[39m dde\u001b[38;5;241m.\u001b[39mModel(data, net_C_L)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Compile the model with the custom loss function\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     50\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:137\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, lr, loss, metrics, decay, loss_weights, external_trainable_variables)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexternal_trainable_variables \u001b[38;5;241m=\u001b[39m external_trainable_variables\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_tensorflow_compat_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_tensorflow(lr, loss_fn, decay)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:186\u001b[0m, in \u001b[0;36mModel._compile_tensorflow_compat_v1\u001b[1;34m(self, lr, loss_fn, decay)\u001b[0m\n\u001b[0;32m    183\u001b[0m         losses \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weights\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n\u001b[1;32m--> 186\u001b[0m losses_train \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m losses_test \u001b[38;5;241m=\u001b[39m losses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mlosses_test)\n\u001b[0;32m    188\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_sum(losses_train)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:172\u001b[0m, in \u001b[0;36mModel._compile_tensorflow_compat_v1.<locals>.losses\u001b[1;34m(losses_fn)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlosses\u001b[39m(losses_fn):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# Data losses\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mlosses_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(losses, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    176\u001b[0m         losses \u001b[38;5;241m=\u001b[39m [losses]\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\data\\data.py:13\u001b[0m, in \u001b[0;36mData.losses_train\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlosses_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, targets, outputs, loss_fn, inputs, model, aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of losses for training dataset, i.e., constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\data\\pde.py:169\u001b[0m, in \u001b[0;36mPDE.losses\u001b[1;34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[0m\n\u001b[0;32m    167\u001b[0m bcs_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, bcs_start))\n\u001b[0;32m    168\u001b[0m error_f \u001b[38;5;241m=\u001b[39m [fi[bcs_start[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] :] \u001b[38;5;28;01mfor\u001b[39;00m fi \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m--> 169\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbkd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, bc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbcs):\n\u001b[0;32m    173\u001b[0m     beg, end \u001b[38;5;241m=\u001b[39m bcs_start[i], bcs_start[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\data\\pde.py:170\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    167\u001b[0m bcs_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, bcs_start))\n\u001b[0;32m    168\u001b[0m error_f \u001b[38;5;241m=\u001b[39m [fi[bcs_start[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] :] \u001b[38;5;28;01mfor\u001b[39;00m fi \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m    169\u001b[0m losses \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 170\u001b[0m     \u001b[43mloss_fn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbkd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, error \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(error_f)\n\u001b[0;32m    171\u001b[0m ]\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, bc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbcs):\n\u001b[0;32m    173\u001b[0m     beg, end \u001b[38;5;241m=\u001b[39m bcs_start[i], bcs_start[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m, in \u001b[0;36mcustom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     20\u001b[0m exponent \u001b[38;5;241m=\u001b[39m (VH \u001b[38;5;241m/\u001b[39m (R \u001b[38;5;241m*\u001b[39m T)) \u001b[38;5;241m*\u001b[39m (sigma_A \u001b[38;5;241m-\u001b[39m sigma_B)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Predictions for C at random points\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m C_A \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_last\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m C_B \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([[x_B, y_B, t_last]])\n\u001b[0;32m     26\u001b[0m constraint_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(C_A \u001b[38;5;241m-\u001b[39m C_B \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(exponent)))\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:890\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, operator, callbacks)\u001b[0m\n\u001b[0;32m    887\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m operator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 890\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\deepxde\\model.py:527\u001b[0m, in \u001b[0;36mModel._outputs\u001b[1;34m(self, training, inputs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow.compat.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    526\u001b[0m     feed_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mfeed_dict(training, inputs)\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    529\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs(training, inputs)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1200\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1197\u001b[0m       feed_map[compat\u001b[38;5;241m.\u001b[39mas_bytes(subfeed_t\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m (subfeed_t, subfeed_val)\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;66;03m# Create a fetch handler to take care of the structure of fetches.\u001b[39;00m\n\u001b[1;32m-> 1200\u001b[0m fetch_handler \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_handles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_handles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;66;03m# Run request and get response.\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;66;03m# We need to keep the returned movers alive for the following _do_run().\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;66;03m# These movers are no longer needed when _do_run() completes, and\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;66;03m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# of a handle from a different device as an error.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_with_movers(feed_dict_tensor, feed_map)\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:489\u001b[0m, in \u001b[0;36m_FetchHandler.__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a fetch handler.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    direct feeds.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 489\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_mapper \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchMapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\yesda\\Documents\\GitHub\\PINN_testing\\.conda\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:266\u001b[0m, in \u001b[0;36m_FetchMapper.for_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates fetch mapper that handles the structure of `fetch`.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03mThe default graph must be the one from which we want to fetch values when\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m  An instance of a subclass of `_FetchMapper` that handles the shape.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    267\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Cannot be None\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fetch, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    269\u001b[0m   \u001b[38;5;66;03m# NOTE(touts): This is also the code path for namedtuples.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ListFetchMapper(fetch)\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument `fetch` = None has invalid type \"NoneType\". Cannot be None"
     ]
    }
   ],
   "source": [
    "# Define the square domain (e.g., 2x2 square with side length L)\n",
    "\n",
    "square = dde.geometry.Rectangle([-L, -L], [L, L])\n",
    "\n",
    "# Define the circular hole at the center (radius R)\n",
    "R = 0.1  # Radius of the hole\n",
    "circle = dde.geometry.Disk([0, 0], R)\n",
    "\n",
    "# Geometry and time domain\n",
    "geom = dde.geometry.csg.CSGDifference(square, circle)\n",
    "timedomain = dde.geometry.TimeDomain(0, t_last)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "# Define the initial condition: C(x, y, 0) = 20\n",
    "def initial_condition(x):\n",
    "    return 20\n",
    "\n",
    "# Define Dirichlet boundary conditions (e.g., C = 0 on the boundaries)\n",
    "def boundary_condition(x, on_boundary):\n",
    "    return on_boundary\n",
    "\n",
    "# Create the initial and boundary conditions\n",
    "ic = dde.icbc.IC(geomtime, lambda x: 20, lambda _, on_initial: on_initial)\n",
    "bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, boundary_condition)\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde_C_L,[ic],\n",
    "    num_domain=1000,\n",
    "    num_boundary=150,\n",
    "    num_initial=180,\n",
    "    num_test=1000,\n",
    "    )\n",
    "\n",
    "# Network for C_L\n",
    "layer_size = [3] + [64] * 3 + [1]  \n",
    "activation = \"tanh\"\n",
    "initializer = \"Glorot uniform\"\n",
    "net_C_L = dde.nn.FNN(layer_size, activation, initializer)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model with the PDE, initial and boundary conditions\n",
    "model= dde.Model(data, net_C_L)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(\"adam\", lr=1e-3, loss=custom_loss)\n",
    "\n",
    "# Train the model\n",
    "losshistory, train_state = model.train(epochs=10000)\n",
    "\n",
    "# Add custom callback for constraint loss\n",
    "losshistory, train_state = model.train(epochs=10000, callbacks=[dde.callbacks.LossTerm(custom_loss)])\n",
    "\n",
    "# Plot and analyze results (optional)\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
